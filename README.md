# Spark with PySpark and JupyterLab

A Docker Compose setup for running PySpark with JupyterLab.

To start the docker container, run the following command:

```bash
docker compose up
```

The JupyterLab is available at [http://localhost:8888](http://localhost:8888).

The Spark UI is available at [http://localhost:4040](http://localhost:4040). (Only after running a Spark job.)
